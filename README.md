# Image-Generation-Using-Stable-Diffusion-and-Comfy-UI
<br>
<h2>üìå Overview </h2>
<p>This project demonstrates image generation using Stable Diffusion within ComfyUI. ComfyUI provides a node-based interface to experiment with different prompts, models, and settings for AI-generated images. The repository contains generated images and their corresponding prompts, along with instructions on how to use ComfyUI for generating new images.</p>
<br>
<h2>üéØ Project Objectives</h2>
‚Ä¢ Utilize Stable Diffusion via ComfyUI for generating high-quality images.<br>
‚Ä¢ Store generated images alongside their input prompts for reference.<br>
‚Ä¢ Provide a structured workflow to use ComfyUI efficiently.<br>
‚Ä¢ Ensure a fully GUI-based, node-controlled workflow without additional coding.<br>
<br>
<h2>‚öôÔ∏è Tools & Technologies</h2>
‚Ä¢ Stable Diffusion (Pre-trained text-to-image model) <br>
‚Ä¢ ComfyUI (Node-based GUI for AI image generation) <br>
<br>
<h2>üì¶ Requirements </h2>
Before running ComfyUI for Stable Diffusion, ensure that your system meets the following requirements. <br>
<h3>üîß Hardware Requirements</h3>
‚Ä¢ Processor: A multi-core CPU (Intel i3/i5 or AMD Ryzen 5/7) or higher. <br>
‚Ä¢ GPU: NVIDIA GPU with at least 4GB VRAM (RTX 3060 or higher recommended) for faster model inference. Works without GPU but slow processing time will be faced. <br>
‚Ä¢ RAM: Minimum 8GB RAM (32GB recommended for handling large models) <br>
‚Ä¢ Storage: At least 40GB of free SSD space to store models and generated images. <br>
<h3>üñ•Ô∏è Software Requirements</h3>
‚Ä¢ Operating System: Windows 10/11, Linux (Ubuntu recommended), or macOS <br>
‚Ä¢ Programming Language: Python 3.8 or higher <br>
‚Ä¢ AI Framework: Stable Diffusion (Hugging Face) <br>
‚Ä¢ Interface & Workflow Engine: ComfyUI <br>
‚Ä¢ Deep Learning Libraries: TensorFlow / PyTorch <br>
‚Ä¢ Dependencies & Packages: NumPy, OpenCV, Matplotlib, PIL, and Hugging Face Diffusers <br>
<br>
<h2>üöÄ Getting Started</h2>
<h3>1Ô∏è‚É£ Downloading ComfyUI</h3>
‚Ä¢ You can download ComfyUI from their official github repository or clone it. <br>
‚Ä¢ Unzip the package and save it in a folder. <br>
<h3>2Ô∏è‚É£ Downloading Stable Diffusion Model</h3>
‚Ä¢ Head over to hugging face to find different versions of Stable diffusion. <br>
‚Ä¢ You can download any available version of Stable diffusion. <br>
<h3>3Ô∏è‚É£ Linking Stable Diffusion model with ComfyUI</h3>
‚Ä¢ Now that you have downloaded the model, head over to ComfyUI folder. <br>
‚Ä¢ Navigate to this path: ComfyUI -> models -> checkpoints<br>
‚Ä¢ Now move your Stable diffusion Model over the specified path. <br>
<h3>4Ô∏è‚É£ Loading the UI</h3>
‚Ä¢ You can view two terminals namely "run_cpu" and "run_nvidia_gpu" at the start of the folder. <br>
‚Ä¢ Double Click/Run "run_nvidia_gpu" if you have a Nvidia gpu in your system or else you can go with "run_cpu" to generate images using CPU. <br>
<h3>5Ô∏è‚É£ Generating Images</h3>
‚Ä¢ Wait for sometime for the interface to load and show up in your browser. <br>
‚Ä¢ It will load in your browser with a local host: 127.0.0.1:8188 <br>
‚Ä¢ You can start giving prompts and generate images by giving suitable positive and negative prompts in the "CLIP Text Encode (Prompt)". <br>
<br>
<h2>üí° Suggestions & Queries </h2>
I highly appreciate any feedback or suggestions to improve this project! <br>
üöÄ If you have:<br>
‚úÖ Ideas for new features or improvements<br>
‚úÖ Found bugs or issues while running the project<br>
<br>
Feel free to open an issue in this repository! <br>
I will do our best to respond as soon as possible. <br>
<hr>
Happy generating! üé®‚ú®
<hr>
